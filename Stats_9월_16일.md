## 회귀분석 (Regession)

선형모형
* x, y는 파라미터가 아니라 데이터
* a, b가 파라미터
* 직선 형태다
* y의 범위가 무한대다
* y의 예측값과 실제값을 MSE로 구할수 있다.

로지스틱 선형모형
* a, b가 파라미터, x,y가 데이터

* x -> y 예측
    * y가 연속인 경우 (y가 범주형인 경우는 분류)
    * 선형 회귀 분석(선형 모형을 이용한 회귀분석)
* '회귀' > 돌아가다

* AIC 중요! Akaike information criterion 높을수록 정확
* OLS는 MSE를 최소화하는 방법

다중공전성(독립변수끼리 예측)
-> 계수 추정이 불안정
-> 조건수 올라감

계수가 크다 - 모형이 할 수 있는 일을 없애다, 설명할 수 있는 일이 적다

과적합: 특정 데이터에만 통하고, 전반적인 트렌드에 해당되지 않을 수 있는 상황. 예측을 하기 어려워진다
* 변수 줄이기
* 계수 줄이기
* 곡선말고 직선으로 하기