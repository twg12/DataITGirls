## 회귀분석 (Regession)

선형모형
* x, y는 파라미터가 아니라 데이터
* a, b가 파라미터
* 직선 형태다
* y의 범위가 무한대다
* y의 예측값과 실제값을 MSE로 구할수 있다.

로지스틱 선형모형
* a, b가 파라미터, x,y가 데이터

* x -> y 예측
    * y가 연속인 경우 (y가 범주형인 경우는 분류)
    * 선형 회귀 분석(선형 모형을 이용한 회귀분석)
* '회귀' > 돌아가다

* AIC 중요! Akaike information criterion 높을수록 정확
* OLS는 MSE를 최소화하는 방법

다중공전성(독립변수끼리 예측)
-> 계수 추정이 불안정
-> 조건수 올라감

계수가 크다 - 모형이 할 수 있는 일을 없애다, 설명할 수 있는 일이 적다

과적합: 특정 데이터에만 통하고, 전반적인 트렌드에 해당되지 않을 수 있는 상황. 예측을 하기 어려워진다
* 변수 줄이기
* 계수 줄이기
* 곡선말고 직선으로 하기

라쏘 vs 릿지: 0이 되는 경향이 덜하며, 예측 성능이 더 좋다. 일반화를 하기 더 좋다. 대신 라쏘는 계수를 없애기에 해석하기 더 편하다
* 계수 절대값을 줄이면 라쓰: ㅣ계수ㅣ
* 제곱을 줄이면 릿지: 계수**2
* 둘다 주리면 엘라스틱 넷

다중공선성: 변수들끼리 예측할 수 있어선 안된다

* 사립학교에서 사회경제적 배경에따라 학생들의 학업성취도 차이가 더 크다