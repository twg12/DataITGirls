# 9월 10일

## 실험복습
* 변수
    * 독립변수: independent variable
    * 종속변수: dependent variable
    * 혼입변수: confounding variable
* 실험: 의도적인 개입이 있어야한다
* 부트스트래핑(시뮬레이션)에서는 두 집단이 같다고 가정한다: 무작의로 나눈다음, 조건을 달리하지 않고 결과를 낸다. 
    * 실험의 경우 조건을 달리한다.
    * 독립변수가 뭐든 같다고 전제로 해놓고 결과가 다른지 분석
* 오류 
    * 1종 오류: "False Alarm" - 차이가 없는데 있다고 나온다.
    * 2종 오류: "Miss" - 차이가 있는데 없다고 나온다.
    * 1종 오류 가능성이 떨어지면 2종 오류 가능성이 올라간다.
* 신뢰수준 = 100 - 유의수준
* 재현성 위기: 남의 실험을 해본다면 같은 결과가 안 나온다. 여러번 실험해봤을 때, 1종 오류 한번은 나오는데, 그걸로 논문을 쓸 때. False Alarm의 일종이며, 논문에 실린 실험을 직접 해봤을 때 논문의 결론대로 안 나온다. 예) Power Pose
```
데이터를 충분히 고문하면 놈은 불게 되어있다
```
* 귀무가설: 귀향/귀성에서의 귀 + 없을 무
    * 같다고 가정하고 실험하지만, 다르다는 결론을 원한다
    * Null Hypothesis
    * H1: 대립가설, H2: 귀무가설

## 효과크기
1. 관찰된 현상의 크기를 나타낸 방법
2. 분산을 이용하는 방법
    * 
3. 평균 차이를 이용하는 방법
    * 표준편차를 이용해서 몇 표준편차 차이가 난다로 설명.
    * IQ

## Eta Squared (에타 제곱)
* 개인차: 집단간 차이 + 집단내 차이
* 에타제곱: 집단간차이/전체차이 (aka 집단SS/전체SS)
    * 집단간 차이: 독립변수에 의한 차이
    전체SS = numpy.sum((X - 전체평균) ** 2)
    * 집단내 차이: 순수한 개인의 특성에 의한 차이
* 에타제곱 1: 모든 것이 실험 조건에 결정된다
  에타제곱 0: 실험 조건과 상관없다
* 코헨's d: 표준편차 차이가 난다

## 진점수 이론 (The Score Theory)
* 진짜 고객 만족도를 구하고 싶다 (T), 설문조사로 만족도 추정(X)
    * X != T
    * X = T + E
* 말을 바꿔 계속 설문조사를 하게 될 경우, 에러부분만 변하게 된다. 
```
    X1 = T + E1
    X2 = T + E2
    X3 = T + E3
------------------
총점 = T + 오차합(0)
```

## MAB
* 강화학습의 가장 단순한 형태
